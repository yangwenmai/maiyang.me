
---
layout: post
title: '习惯养成记之03'
keywords: 习惯, 时间管理
date: 2017-03-15 06:40
description: '习惯养成记之03'
categories: [习惯]
tags: [习惯]
comments: true
group: archive
icon: file-o
---

昨天是习惯养成记的第二天，有了第一天的经验，我也改变了我的执行工具，由微信读书改为kindle了，可能是早上走的太晚了，上地铁时过于拥挤导致我从一开始就觉得很不适应，一个手拿kindle的空间都没有，着实让我有点抓狂。

<!-- more -->

整个早上的阅读过程也不是非常顺畅，先是拥挤的空间，随后是睡眼朦胧。再加上之前一天已经看过了《巨婴国》的部分内容，对其中所阐述的观点不是很认同。后面更多的也是各种案例所折射出来的所谓心理学结论，所以我并没有完整精读了。

在昨天晚上回家路上概览阅读完整书，就更换了阅读的书籍《图解Spark》。

说到这本书，我想说的是，大家买书一定要到正规渠道去买，不怕大家笑话或鄙视，这本书我是淘宝上买的，所以结果你懂的。

影印质量非常差，甚至还有影响阅读的不清晰的图片。

通过本书，我希望对大数据基础框架平台有一个完整认识，方便自己了解数据，了解如何开始数据分析，通过数据分析来为产品决策或者说产品优化提供方向和数据支撑。

###阅读笔记###

- Spark 简介
	1. Spark 是什么
		- Spark是AMP实验室开发的通用大数据处理框架，Spark生态系统也称为BDAS，力图在算法、机器、人之间通过大规模集成来展现大数据应用的一个开源平台。
		- Spark的特点：1. 运行速度快 2. 易用性好 3. 通用性强 4. 随处运行
	2. Spark 与 MapReduce 比较
		- Spark 是借鉴 Hadoop MapReduce 发展而来的，继承了其分布式并行计算的优点，改进了 MapReduce 明显的缺陷。
		- Spark 将中间数据放在内存，迭代运算效率高。Spark支持 DAG 图的分布式并行计算的编程框架，减少了迭代过程中数据的落地，提高了处理效率。
		- Spark 的容错性高。引进了RDD的概念。
		- Spark 更加通用。
	3. Spark 的演进路线图
		- Spark 由 Lester 和 Matei 在 2009 年算法比赛的思想碰撞中诞生。
		- 2009 年由 Berkeley's AMPLab 开始编写最初的源代码。
		- 2010 年开放源代码
		- 2012 年 2 月发布 0.6.0 版本
		- 2013 年 6 月进入 Apache 孵化器项目
		- 2013 年年中 Spark 主要成员创立 Databricks 公司
		- 2014 年 2 月成为 Apache 顶级项目（耗时8个月时间）
		- 2014 年 5 月底 Spark 1.0.0 发布
		- 2014 年 9 月 Spark 1.1.0 发布
		- 2014 年 12 月 Spark 1.2.0 发布
		- 2015 年 3 月 Spark 1.3.0 发布
		- 2015 年 6 月 Spark 1.4.0 发布
		- 2015 年 9 月 Spark 1.5.0 发布
		- 2016 年 1 月 Spark 1.6.0 发布
		- 2016 年 5 月 Spark 2.0.0 Preview版本发布
		- 2016 年 7 月 Spark 2.0.0 正式版本发布

- Spark 生态系统
	1. Spark Core
		- 整个 BDAS 生态系统的核心组件，是一个分布式大数据处理框架。
		- 提供了多种资源调度管理，通过内存计算、有向无环图(DAG)等机制保证分布式计算的快速，并引入了RDD的抽象保证数据的高容错性。
		- 提供了多种运行模式：本地模式，Standalone，第三方调度框架：YARN,MESOS等
	2. Spark Streaming
		- 是一个对实时数据流进行高吞吐、高容错的流式处理系统，可以对多种数据源进行类似Map、Reduce 和 Join等复杂操作，并将结果保存到外部文件系统、数据库或应用到实时仪表盘。
		- 动态负载均衡
		- 快速故障恢复机制
		- 批处理、流处理与交互式分析的一体化
	3. Spark SQL
		- 前身是 Shark，即 Hive On Spark
		- 2014 年 7 月 1 日的 Spark Summit 上，Databricks 宣布终止对 Shark 的开发，将重点放到 Spark SQL
		- 引入新的 RDD 类型：SchemaRDD，可以抽象传统数据库定义表一样来定义SchemaRDD。
		- 内嵌了 Catalyst 查询优化框架
		- 在应用程序中可以混用不同来源的数据。
		- Spark SQL 做的几点优化：内存列存储，字节码生成技术，Scala 代码优化。
	4. BlinkDB
		- 是一个用于在海量数据上运行交互式SQL查询的大规模并行查询引擎，它允许用户通过权衡数据精度来提升查询响应时间，其数据的精度被控制在允许的误差范围内。
		- 自适应优化框架
		- 动态样本选择策略
	5. MLBase/MLlib
	6. GraphX
	7. SparkR
	8. Alluxio


###总结###

1. 在地铁上看纸质书不是很方便。
2. 对于心理学类的书籍，不需要精度，了解一种观点一种认识即可。
3. kindle看书不方便做笔记。

### 延伸阅读 ###

1. 在闲暇时，有在看《自制力》

----

**茶歇驿站**

一个让你可以在茶歇之余，停下来看一看，里面的内容或许对你有一些帮助。

这里的内容主要是团队管理，个人管理，后台技术相关，其他个人杂想。

![茶歇驿站二维码](http://ww4.sinaimg.cn/large/824dcde4gw1f358o5j022j20by0bywf8.jpg)
